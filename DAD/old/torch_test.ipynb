{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bayesflow/lib/python3.11/site-packages/keras/src/backend/torch/numpy.py:870: UserWarning: The operator 'aten::logspace.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1715184405838/work/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  torch.logspace(\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import keras\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import bayesflow as bf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "import bayesflow as bf\n",
    "from bayesflow.utils import filter_concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bayesflow as bf\n",
    "from torch import Tensor\n",
    "from torch.distributions import Distribution\n",
    "\n",
    "from custom_simulators import LikelihoodBasedModel, ParameterMask, Prior, RandomNumObs\n",
    "from design_networks import RandomDesign, DeepAdaptiveDesign, EmitterNetwork\n",
    "from design_loss import NestedMonteCarlo\n",
    "from inference_design_approximator import JointApproximator\n",
    "from custom_dataset import DataSet\n",
    "\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression(LikelihoodBasedModel):\n",
    "    def __init__(self, mask_sampler, prior_sampler, tau_sampler, design_generator, sim_vars) -> None:\n",
    "        super().__init__(mask_sampler, prior_sampler, tau_sampler, design_generator, sim_vars)\n",
    "\n",
    "    def outcome_likelihood(self, params: Tensor, xi: Tensor, sim_vars: dict) -> Distribution: # params: [B, param_dim], xi: [B, 1, xi_dim]\n",
    "        xi_powers = torch.stack([torch.ones_like(xi), xi, xi ** 2, xi ** 3], dim=-2).squeeze(-1) # [B, 1, 4]\n",
    "        mean = torch.sum(params.unsqueeze(1) * xi_powers, dim=-1, keepdim=True) # sum([B, 1, 4] * [B, 1, 4]) = [B, 1, y_dim] (y_dim = 1 here)\n",
    "        sigma = sim_vars[\"sigma\"]\n",
    "        return torch.distributions.Normal(mean, sigma) # [B, 1, y_dim]\n",
    "    \n",
    "    def analytical_log_marginal_likelihood(outcomes, params: Tensor, masks: Tensor) -> Tensor:\n",
    "        raise NotImplementedError # TODO\n",
    "\n",
    "class PriorPolynomialReg(Prior):\n",
    "    def __init__(self, delta: Tensor = Tensor([0.1])) -> None:\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def dist(self, masks: Tensor) -> Distribution:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.masks = masks\n",
    "\n",
    "        default = Tensor([[0, self.delta]])\n",
    "        masks_ = masks.unsqueeze(-1)\n",
    "\n",
    "        prior_0 = torch.where(masks_[:, 0] == 1, Tensor([5, 2]), default)\n",
    "        prior_1 = torch.where(masks_[:, 1] == 1, Tensor([3, 1]), default)\n",
    "        prior_2 = torch.where(masks_[:, 2] == 1, Tensor([0, 0.8]), default)\n",
    "        prior_3 = torch.where(masks_[:, 3] == 1, Tensor([0, 0.5]), default)\n",
    "\n",
    "        hyper_params = torch.stack([prior_0, prior_1, prior_2, prior_3], dim=1)\n",
    "\n",
    "        means = hyper_params[:, :, 0]\n",
    "        sds = hyper_params[:, :, 1]\n",
    "    \n",
    "        dist = torch.distributions.MultivariateNormal(means, scale_tril=torch.stack([torch.diag(sd) for sd in sds])) # [B, theta_dim]\n",
    "\n",
    "        return dist\n",
    "    \n",
    "inference_network = bf.networks.FlowMatching() # TODO replace with coupling flow bf.networks.CouplingFlow()\n",
    "summary_network = bf.networks.DeepSet(summary_dim = 10)\n",
    "\n",
    "approximator = bf.Approximator(\n",
    "    inference_network = inference_network,\n",
    "    summary_network = summary_network,\n",
    "    inference_variables = [\"params\"],\n",
    "    inference_conditions = [\"masks\", \"n_obs\"],\n",
    "    summary_variables = [\"outcomes\", \"designs\"]\n",
    ")\n",
    "\n",
    "T = 20 # number of maximum experiments (resources)\n",
    "design_shape = torch.Size([1])\n",
    "mask_sampler = ParameterMask()\n",
    "prior_sampler = PriorPolynomialReg()\n",
    "random_num_obs = RandomNumObs(min_obs = 1, max_obs = T)\n",
    "random_design_generator = RandomDesign(design_shape = design_shape)\n",
    "\n",
    "model_1 = PolynomialRegression(mask_sampler = mask_sampler,\n",
    "                                        prior_sampler = prior_sampler,\n",
    "                                        tau_sampler = random_num_obs,\n",
    "                                        design_generator = random_design_generator,\n",
    "                                        sim_vars = {\"sigma\": 1.0})\n",
    "\n",
    "decoder_net = EmitterNetwork(input_dim = 10, hidden_dim = 24, output_dim = 1) # [B, summary_dim] -> [B, design_dim]\n",
    "design_net = DeepAdaptiveDesign(encoder_net = approximator.summary_network,\n",
    "                                decoder_net = decoder_net,\n",
    "                                design_shape = design_shape, \n",
    "                                summary_variables=[\"outcomes\", \"designs\"])\n",
    "\n",
    "model_2 = PolynomialRegression(mask_sampler = mask_sampler,\n",
    "                                        prior_sampler = prior_sampler,\n",
    "                                        tau_sampler = random_num_obs,\n",
    "                                        design_generator = design_net,\n",
    "                                        sim_vars = {\"sigma\": 1.0})\n",
    "\n",
    "\n",
    "class DeepAdaptiveDesign(nn.Module):\n",
    "  def __init__(\n",
    "      self,\n",
    "      encoder_net: nn.Module | bf.networks.DeepSet, # same summary for bf and dad or different?\n",
    "      decoder_net: nn.Module,\n",
    "      design_shape: torch.Size, # [xi_dim]\n",
    "      summary_variables: list[str] = None # in case of using summary_net from bf\n",
    "    ) -> None:\n",
    "    super().__init__()\n",
    "    self.design_shape = design_shape\n",
    "    self.register_parameter(\n",
    "        \"initial_design\",\n",
    "        nn.Parameter(0.1 * torch.ones(design_shape, dtype=torch.float32)) # scalar\n",
    "    )\n",
    "    self.encoder_net = encoder_net\n",
    "    self.decoder_net = decoder_net\n",
    "    self.summary_variables = summary_variables\n",
    "\n",
    "  def forward(self, history, batch_size: int) -> Tensor:\n",
    "\n",
    "    if history is None:\n",
    "      return self.initial_design\n",
    "    else:\n",
    "      # embed design-outcome pairs\n",
    "      # embeddings = self.encoder_net(filter_concatenate(history, keys=self.summary_variables)).to('cpu').requires_grad_(True)  # in case of using summary_net from bf. [B, summary_dim]\n",
    "      # embeddings = torch.rand([1, 10], requires_grad=True)\n",
    "      # get next design\n",
    "      next_design = self.decoder_net(embeddings)\n",
    "    return next_design\n",
    "\n",
    "# hyperparams for bf\n",
    "B = 32\n",
    "batch_shape_b = torch.Size([B])\n",
    "\n",
    "# hyperparams for DAD\n",
    "B_d = 2000 # number of poitive samples\n",
    "batch_shape_d = torch.Size([B_d])\n",
    "L = 2000 # number of negative samples\n",
    "\n",
    "dataset = DataSet(batch_shape = batch_shape_b, \n",
    "                    joint_model_1 = model_1,\n",
    "                    joint_model_2 = model_2)\n",
    "\n",
    "pce_loss = NestedMonteCarlo(approximator = approximator,\n",
    "                            joint_model = model_2, # joint model with design network\n",
    "                            batch_shape = batch_shape_d,\n",
    "                            num_negative_samples = L)\n",
    "\n",
    "trainer = JointApproximator(\n",
    "    approximator = approximator,\n",
    "    design_loss = pce_loss,\n",
    "    dataset = dataset\n",
    ")\n",
    "\n",
    "# hyper_params = {\"epochs_1\": 1, \"steps_per_epoch_1\": 1,\n",
    "#                 \"epochs_2\": 1, \"steps_per_epoch_2\": 100,\n",
    "#                 \"epochs_3\": 5, \"steps_per_epoch_3\": 100}\n",
    "\n",
    "# PATH = \"test\"  # ...BayesFlow/DAD/test/\n",
    "# trainer.train(PATH = PATH, **hyper_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_1.sample(torch.Size([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input requires grad: True\n",
      "Input requires grad: False\n",
      "Input requires grad: False\n",
      "Input requires grad: False\n"
     ]
    }
   ],
   "source": [
    "out = design_net(history, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepAdaptiveDesign(nn.Module):\n",
    "  def __init__(\n",
    "      self,\n",
    "      # encoder_net: nn.Module, # same summary for bf and dad or different?\n",
    "      decoder_net: nn.Module,\n",
    "      design_shape: torch.Size, # [xi_dim]\n",
    "      summary_variables: list[str] = None # in case of using summary_net from bf\n",
    "    ) -> None:\n",
    "    super().__init__()\n",
    "    self.design_shape = design_shape\n",
    "    self.register_parameter(\n",
    "        \"initial_design\",\n",
    "        nn.Parameter(0.1 * torch.ones(design_shape, dtype=torch.float32)) # scalar\n",
    "    )\n",
    "    # self.encoder_net = encoder_net\n",
    "    self.decoder_net = decoder_net\n",
    "    self.summary_variables = summary_variables\n",
    "\n",
    "  def forward(self, history, batch_size: int) -> Tensor:\n",
    "\n",
    "    if history is None:\n",
    "      return self.initial_design\n",
    "    else:\n",
    "      # embed design-outcome pairs\n",
    "      # embeddings = self.encoder_net(filter_concatenate(history, keys=self.summary_variables)).to('cpu').requires_grad_(True)  # in case of using summary_net from bf. [B, summary_dim]\n",
    "      embeddings = torch.rand([1, 10], requires_grad=True)\n",
    "      # get next design\n",
    "      next_design = self.decoder_net(embeddings)\n",
    "    return next_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmitterNetwork(nn.Module):\n",
    "  def __init__(\n",
    "        self,\n",
    "        input_dim, # summary_dim\n",
    "        hidden_dim,\n",
    "        output_dim, # xi_dim\n",
    "        n_hidden_layers=2,\n",
    "        activation=nn.Softplus,\n",
    "    ):\n",
    "    super().__init__()\n",
    "    self.activation_layer = activation()\n",
    "    self.input_layer = nn.Linear(input_dim, hidden_dim)\n",
    "    if n_hidden_layers > 1:\n",
    "      self.middle = nn.Sequential(\n",
    "         *[\n",
    "            nn.Sequential(nn.Linear(hidden_dim, hidden_dim), activation())\n",
    "            for _ in range(n_hidden_layers - 1)\n",
    "          ]\n",
    "            )\n",
    "    else:\n",
    "      self.middle = nn.Identity()\n",
    "      \n",
    "    self.output_layer = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "  def forward(self, r):\n",
    "    print(\"Input requires grad:\", r.requires_grad) \n",
    "    x = self.input_layer(r)\n",
    "    print(\"Input requires grad:\", x.requires_grad) \n",
    "    x = self.activation_layer(x)\n",
    "    print(\"Input requires grad:\", x.requires_grad) \n",
    "    x = self.middle(x)\n",
    "    print(\"Input requires grad:\", x.requires_grad) \n",
    "    x = self.output_layer(x)\n",
    "    return x.unsqueeze(1) # [B, xi_dim] -> [B, 1, xi_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Simulator(nn.Module):\n",
    "    def __init__(self, design_net):\n",
    "        super().__init__()\n",
    "        self.design_net = design_net\n",
    "    \n",
    "    def forward(self):\n",
    "        out = []\n",
    "\n",
    "        for i in range(5):\n",
    "            out.append(self.design_net(None, 0))\n",
    "\n",
    "        out = torch.cat(out, dim=0)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = EmitterNetwork(10, 24, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "design_net = DeepAdaptiveDesign(\n",
    "    decoder_net=decoder,\n",
    "    design_shape=torch.Size([1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.rand([1, 10], requires_grad=True) # same dimension as embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input requires grad: True\n",
      "Input requires grad: False\n",
      "Input requires grad: False\n",
      "Input requires grad: False\n"
     ]
    }
   ],
   "source": [
    "output = decoder(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_design = design_net(None, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([0.1000], requires_grad=True)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Simulator(design_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = simulator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1000, 0.1000, 0.1000, 0.1000, 0.1000])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
