{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use torch backend\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "\n",
    "import keras\n",
    "\n",
    "if keras.backend.backend() == \"torch\":\n",
    "    import torch\n",
    "    print(\"Use torch backend\")\n",
    "    torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import bayesflow as bf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.simulators.simulator import Simulator\n",
    "# from bayesflow.types import Shape, Tensor\n",
    "from torch import Tensor\n",
    "from torch.distributions import Distribution\n",
    "import torch.nn as nn\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGenericSimulator(Simulator):\n",
    "    def __init__(self, context_sampler: Callable, prior_sampler: Callable, tau_sampler: Callable, design_generator: nn.Module, simulator_var: dict):\n",
    "        self.context_sampler = context_sampler\n",
    "        self.prior_sampler = prior_sampler\n",
    "        self.tau_sampler = tau_sampler\n",
    "        self.design_generator = design_generator\n",
    "        self.simulator_var = simulator_var\n",
    "\n",
    "    def sample(self, batch_size: torch.Size, **kwargs) -> dict[str, Tensor]:\n",
    "\n",
    "        context = self.context_sampler(batch_size)\n",
    "        params = self.prior_sampler.sample(context)\n",
    "        tau = self.tau_sampler()\n",
    "        \n",
    "        designs = []\n",
    "        outcomes = []\n",
    "\n",
    "        for t in range(tau):\n",
    "            xi = self.design_generator(batch_size)\n",
    "\n",
    "            # if params.shape[0] != xi.shape[0]: # for initial design\n",
    "            #     xi = xi.repeat(params.shape[0], 1)\n",
    "\n",
    "            y = self.outcome_simulator(params=params, xi=xi, simulator_var = self.simulator_var)\n",
    "\n",
    "            designs.append(xi)\n",
    "            outcomes.append(y)\n",
    "\n",
    "        designs = torch.stack(designs, dim=1) #  [B, tau]\n",
    "        outcomes = torch.stack(outcomes, dim=1).squeeze(-1) # [B, tau]\n",
    "        n_obs = tau.repeat(batch_size).unsqueeze(1) # [B, 1]\n",
    "\n",
    "        out = {\"context\": context, \"params\": params, \"n_obs\": n_obs, \"designs\": designs, \"outcomes\": outcomes}\n",
    "\n",
    "        return out\n",
    "    \n",
    "    def outcome_simulator(self, params: Tensor, xi: Tensor) -> Tensor:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDesign(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, batch_size: torch.Size, designs: [Tensor] = None, outcomes: [Tensor] = None) -> Tensor:\n",
    "        return torch.rand(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LikelihoodBasedModel(MyGenericSimulator):\n",
    "    def __init__(self, context_sampler, prior_sampler, tau_sampler, design_generator, simulator_var) -> None:\n",
    "        super().__init__(context_sampler, prior_sampler, tau_sampler, design_generator, simulator_var)\n",
    "\n",
    "    def outcome_likelihood(self, params: Tensor, xi: Tensor, simulator_var: dict) -> Distribution:\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def outcome_simulator(self, params: Tensor, xi: Tensor, simulator_var: dict) -> Tensor:\n",
    "        return self.outcome_likelihood(params, xi, simulator_var).sample()\n",
    "    \n",
    "    def approximate_log_marginal_likelihood(self, params: Tensor, outcomes: Tensor, log_approx_posterior):\n",
    "        firt_term = self.outcome_likelihood(parms, xi, simulator_var).log_prob(outcomes) \n",
    "        second_term = self.prior_sampler.log_prob(params)\n",
    "        third_term = log_approx_posterior.log_prob(prams, outcomes, xi).mean()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression(LikelihoodBasedModel):\n",
    "    def __init__(self, context_sampler, prior_sampler, tau_sampler, design_generator, simulator_var) -> None:\n",
    "        super().__init__(context_sampler, prior_sampler, tau_sampler, design_generator, simulator_var)\n",
    "\n",
    "    def outcome_likelihood(self, params: Tensor, xi: Tensor, simulator_var: dict) -> Distribution:\n",
    "\n",
    "        xi_powers = torch.stack([torch.ones_like(xi), xi, xi ** 2, xi ** 3], dim=1)\n",
    "        mean = torch.sum(params * xi_powers, dim=-1, keepdim=True)\n",
    "        sigma = simulator_var[\"sigma\"]\n",
    "        return torch.distributions.Normal(mean, sigma)\n",
    "    \n",
    "    def analytical_log_marginal_likelihood(outcomes, params: Tensor, param_mask: Tensor) -> Tensor:\n",
    "        raise NotImplementedError # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParameterMask:\n",
    "    def __init__(self, num_parameters: int = 4, possible_masks: Tensor = None) -> None:\n",
    "        default_mask = torch.tril(torch.ones((num_parameters, num_parameters)))\n",
    "        self.num_parameters = num_parameters\n",
    "        self.possible_masks = torch.tensor(possible_masks, dtype=torch.float32) if possible_masks is not None else default_mask\n",
    "\n",
    "    def __call__(self, batch_shape: torch.Size) -> Tensor:\n",
    "        index_samples = torch.randint(0, self.possible_masks.shape[0], batch_shape, dtype=torch.long)\n",
    "        out_mask = self.possible_masks[index_samples]\n",
    "\n",
    "        return out_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior():\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "    \n",
    "    def dist_list(self, param_mask: Tensor) -> [Distribution]:\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def sample(self, param_mask: Tensor) -> Tensor:\n",
    "        return torch.stack([dist.sample() for dist in self.dist_list(param_mask)], dim = 0)\n",
    "\n",
    "    def log_prob(self, params: Tensor) -> Tensor:\n",
    "        return torch.stack([dist.log_prob(param) for dist, param in zip(self.dist_list(param_mask), params)], dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorPolynomialReg(Prior):\n",
    "    def __init__(self, delta: Tensor = Tensor([0.1])) -> None:\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def dist_list(self, param_mask: Tensor) -> [Distribution]:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.param_mask = param_mask\n",
    "\n",
    "        default = Tensor([[0, self.delta]])\n",
    "        param_mask_unsq = param_mask.unsqueeze(-1)\n",
    "\n",
    "        prior_0 = torch.where(param_mask_unsq[:, 0] == 1, Tensor([5, 2]), default)\n",
    "        prior_1 = torch.where(param_mask_unsq[:, 1] == 1, Tensor([3, 1]), default)\n",
    "        prior_2 = torch.where(param_mask_unsq[:, 2] == 1, Tensor([0, 0.8]), default)\n",
    "        prior_3 = torch.where(param_mask_unsq[:, 3] == 1, Tensor([0, 0.5]), default)\n",
    "\n",
    "        hyper_params = torch.stack([prior_0, prior_1, prior_2, prior_3], dim=1)\n",
    "\n",
    "        mean_s = hyper_params[:, :, 0]\n",
    "        sigma_s = hyper_params[:, :, 1]\n",
    "    \n",
    "        dist_list = [torch.distributions.MultivariateNormal(mean, scale_tril=torch.diag(sigma)) for mean, sigma in zip(mean_s, sigma_s)]\n",
    "\n",
    "        return dist_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = torch.Size([20])\n",
    "\n",
    "param_mask_generator = ParameterMask()\n",
    "param_mask = param_mask_generator(batch_size)\n",
    "polynomial_reg = PriorPolynomialReg()\n",
    "params = polynomial_reg.sample(param_mask)\n",
    "likelihood = polynomial_reg.log_prob(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of parameter mask torch.Size([20, 4])\n",
      "Shape of parameters torch.Size([20, 4])\n",
      "Shape of likelihood torch.Size([20])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of parameter mask {param_mask.shape}\") # [B, model_dim]\n",
    "print(f\"Shape of parameters {params.shape}\") # [B, param_dim]\n",
    "print(f\"Shape of likelihood {likelihood.shape}\") # [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_mask = ParameterMask()\n",
    "random_design_generator = RandomDesign()\n",
    "prior = PriorPolynomialReg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "def random_num_obs(min_obs : int = 1, max_obs : int = T) -> Tensor:\n",
    "    return torch.randint(min_obs, max_obs + 1, (1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_reg = PolynomialRegression(context_sampler = parameter_mask,\n",
    "                                      prior_sampler = prior,\n",
    "                                      tau_sampler = random_num_obs,\n",
    "                                      design_generator = random_design_generator,\n",
    "                                      simulator_var = {\"sigma\": 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = polynomial_reg.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['context', 'params', 'n_obs', 'designs', 'outcomes'])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(keras.utils.PyDataset):\n",
    "    def __init__(self, batch_size: torch.Size, stage: int, initial_generative_model: MyGenericSimulator, design_network: nn.Module = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.stage = stage # stage 1,2,3\n",
    "        self.initial_generative_model = initial_generative_model\n",
    "        self.design_network = design_network\n",
    "\n",
    "    def __getitem__(self, item:int) -> dict[str, Tensor]:\n",
    "        if self.stage == 1:\n",
    "\n",
    "            data = self.initial_generative_model.sample(self.batch_size)\n",
    "            return data\n",
    "\n",
    "        if self.stage == 2:\n",
    "            second_generative_model = 1\n",
    "            data = self.second_generative_model.sampel(self.batch_size, )\n",
    "            return data\n",
    "\n",
    "        if self.stage == 3:\n",
    "            ...\n",
    "            return data\n",
    "    \n",
    "    @property\n",
    "    def num_batches(self):\n",
    "        # infinite dataset\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataSet(batch_size = batch_size, stage = 1, initial_generative_model = polynomial_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_network = bf.networks.CouplingFlow(depth = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = bf.networks.DeepSet(summary_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator = bf.Approximator(\n",
    "    inference_network = inference_network,\n",
    "    summary_network = summary_network,\n",
    "    inference_variables = [\"params\"],\n",
    "    inference_conditions = [\"context\", \"n_obs\"],\n",
    "    summary_variables = [\"outcomes\", \"designs\"]\n",
    ")\n",
    "\n",
    "approximator.compile(optimizer=\"AdamW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Trainer.compute_metrics() got an unexpected keyword argument 'stage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[173], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mapproximator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis/dad_bf_newapi/BayesFlow/examples/../bayesflow/approximators/base_approximator.py:168\u001b[0m, in \u001b[0;36mBaseApproximator.fit\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot automatically build the approximator. Please pass a dataset as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument to `approximator.fit()` or manually call `approximator.build()` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwith a dictionary specifying your data shapes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    167\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(dataset))\n\u001b[0;32m--> 168\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild_from_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mfit(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/thesis/dad_bf_newapi/BayesFlow/examples/../bayesflow/approximators/base_approximator.py:95\u001b[0m, in \u001b[0;36mBaseApproximator.build_from_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbuild_from_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Tensor]):\n\u001b[0;32m---> 95\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/thesis/dad_bf_newapi/BayesFlow/examples/../bayesflow/approximators/base_approximator.py:134\u001b[0m, in \u001b[0;36mBaseApproximator.compute_metrics\u001b[0;34m(self, data, stage)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minference_network\u001b[38;5;241m.\u001b[39mcompute_metrics(data, stage\u001b[38;5;241m=\u001b[39mstage)\n\u001b[1;32m    132\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigurator\u001b[38;5;241m.\u001b[39mconfigure_summary_variables(data)\n\u001b[0;32m--> 134\u001b[0m summary_metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msummary_network\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msummary_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m summary_metrics\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    138\u001b[0m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minference_variables\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfigurator\u001b[38;5;241m.\u001b[39mconfigure_inference_variables(data)\n",
      "\u001b[0;31mTypeError\u001b[0m: Trainer.compute_metrics() got an unexpected keyword argument 'stage'"
     ]
    }
   ],
   "source": [
    "approximator.fit(dataset, epochs=1, steps_per_epoch=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO at last\n",
    "\n",
    "class InferenceDesignApproximator:\n",
    "    def __init__(self, hyperparameters: dict, bf_settings: dict, design_settings: dict):\n",
    "\n",
    "        self.summary_network = ...\n",
    "\n",
    "        # Dataset object: online dataset https://github.com/stefanradev93/BayesFlow/blob/streamlined-backend/bayesflow/datasets/online_dataset.py\n",
    "        self.dataset: MyDataSet\n",
    "\n",
    "        # BayesFlow approximator is encapsuled\n",
    "        self.bf_approximator = bf.approximators.Approximator(..., summary_network, **bf_settings)\n",
    "        \n",
    "        # Design network object is encapsuled\n",
    "        self.design_net = DesignNetwork(..., summary_network, **design_settings)\n",
    "\n",
    "        # Hyperparameters: weight terms to balance losses, etc.\n",
    "        self.hyperparameters = hyperparameters\n",
    "\n",
    "    def train(self, dataset):\n",
    "        # Stage 1: Train Bayesflow, use random design\n",
    "        self.bf_approximator.train(dataset)\n",
    "        self.dataset.stage = 2\n",
    "\n",
    "        # Stage 2: Fix BayesFlow, train design network\n",
    "        self.bf_approximator.freeze_weights() # implement this\n",
    "        self.design_approximator.train(dataset)\n",
    "        self.dataset.stage = 3\n",
    "\n",
    "        # Stage 3: Joint training"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
