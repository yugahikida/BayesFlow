{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use torch backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bayesflow/lib/python3.11/site-packages/keras/src/backend/torch/numpy.py:870: UserWarning: The operator 'aten::logspace.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1715184405838/work/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  torch.logspace(\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import keras\n",
    "\n",
    "if keras.backend.backend() == \"torch\":\n",
    "    import torch\n",
    "    print(\"Use torch backend\")\n",
    "    torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import bayesflow as bf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.simulators.simulator import Simulator\n",
    "# from bayesflow.types import Shape, Tensor\n",
    "from torch import Tensor\n",
    "from torch.distributions import Distribution\n",
    "import torch.nn as nn\n",
    "from typing import Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_simulators import MyGenericSimulator, LikelihoodBasedModel, ParameterMask, Prior, RandomNumObs\n",
    "from design_networks import RandomDesign, DeepAdaptiveDesign\n",
    "from design_loss import NestedMonteCarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression(LikelihoodBasedModel):\n",
    "    def __init__(self, mask_sampler, prior_sampler, tau_sampler, design_generator, simulator_var) -> None:\n",
    "        super().__init__(mask_sampler, prior_sampler, tau_sampler, design_generator, simulator_var)\n",
    "\n",
    "    def outcome_likelihood(self, params: Tensor, xi: Tensor, simulator_var: dict) -> Distribution:\n",
    "\n",
    "        xi_powers = torch.stack([torch.ones_like(xi), xi, xi ** 2, xi ** 3], dim=1)\n",
    "        mean = torch.sum(params * xi_powers, dim=-1, keepdim=True)\n",
    "        sigma = simulator_var[\"sigma\"]\n",
    "        return torch.distributions.Normal(mean, sigma)\n",
    "    \n",
    "    def analytical_log_marginal_likelihood(outcomes, params: Tensor, masks: Tensor) -> Tensor:\n",
    "        raise NotImplementedError # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorPolynomialReg(Prior):\n",
    "    def __init__(self, delta: Tensor = Tensor([0.1])) -> None:\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def dist(self, masks: Tensor) -> [Distribution]:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.masks = masks\n",
    "\n",
    "        default = Tensor([[0, self.delta]])\n",
    "        masks_ = masks.unsqueeze(-1)\n",
    "\n",
    "        prior_0 = torch.where(masks_[:, 0] == 1, Tensor([5, 2]), default)\n",
    "        prior_1 = torch.where(masks_[:, 1] == 1, Tensor([3, 1]), default)\n",
    "        prior_2 = torch.where(masks_[:, 2] == 1, Tensor([0, 0.8]), default)\n",
    "        prior_3 = torch.where(masks_[:, 3] == 1, Tensor([0, 0.5]), default)\n",
    "\n",
    "        hyper_params = torch.stack([prior_0, prior_1, prior_2, prior_3], dim=1)\n",
    "\n",
    "        means = hyper_params[:, :, 0]\n",
    "        sds = hyper_params[:, :, 1]\n",
    "    \n",
    "        dist = torch.distributions.MultivariateNormal(means, scale_tril=torch.stack([torch.diag(sd) for sd in sds]))\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 64\n",
    "batch_size = torch.Size([B])\n",
    "\n",
    "mask_sampler = ParameterMask()\n",
    "masks = mask_sampler(batch_size)\n",
    "prior_sampler = PriorPolynomialReg()\n",
    "params = prior_sampler.sample(masks)\n",
    "likelihood = prior_sampler.log_prob(params, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of parameter mask {masks.shape}\") # [B, model_dim]\n",
    "print(f\"Shape of parameters {params.shape}\") # [B, param_dim]\n",
    "print(f\"Shape of likelihood {likelihood.shape}\") # [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_design_generator = RandomDesign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "random_num_obs = RandomNumObs(min_obs = 1, max_obs = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_reg = PolynomialRegression(mask_sampler = mask_sampler,\n",
    "                                      prior_sampler = prior_sampler,\n",
    "                                      tau_sampler = random_num_obs,\n",
    "                                      design_generator = random_design_generator,\n",
    "                                      simulator_var = {\"sigma\": 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(keras.utils.PyDataset):\n",
    "    def __init__(self, batch_size: torch.Size, stage: int, initial_generative_model: MyGenericSimulator, design_network: nn.Module = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.stage = stage # stage 1,2,3\n",
    "        self.initial_generative_model = initial_generative_model\n",
    "        self.design_network = design_network\n",
    "\n",
    "    def __getitem__(self, item:int) -> dict[str, Tensor]:\n",
    "        if self.stage == 1:\n",
    "\n",
    "            data = self.initial_generative_model.sample(self.batch_size)\n",
    "            return data\n",
    "\n",
    "        if self.stage == 2:\n",
    "            second_generative_model = 1\n",
    "            data = self.second_generative_model.sampel(self.batch_size, )\n",
    "            return data\n",
    "\n",
    "        if self.stage == 3:\n",
    "            ...\n",
    "            return data\n",
    "    \n",
    "    @property\n",
    "    def num_batches(self):\n",
    "        # infinite dataset\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataSet(batch_size = batch_size, stage = 1, initial_generative_model = polynomial_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unrecognized keyword arguments passed to FlowMatching: {'depth': 8}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m inference_network \u001b[38;5;241m=\u001b[39m \u001b[43mbf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnetworks\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlowMatching\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdepth\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubnet_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkernel_regularizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdropout_prob\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/thesis/BayesFlow_DAD/DAD/../bayesflow/networks/flow_matching/flow_matching.py:23\u001b[0m, in \u001b[0;36mFlowMatching.__init__\u001b[0;34m(self, subnet, base_distribution, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, subnet: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmlp\u001b[39m\u001b[38;5;124m\"\u001b[39m, base_distribution: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 23\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mbase_distribution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_distribution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkeras_kwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubnet \u001b[38;5;241m=\u001b[39m find_network(subnet, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubnet_kwargs\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}))\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_projector \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(units\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, bias_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m, kernel_initializer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/thesis/BayesFlow_DAD/DAD/../bayesflow/networks/inference_network.py:9\u001b[0m, in \u001b[0;36mInferenceNetwork.__init__\u001b[0;34m(self, base_distribution, **kwargs)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, base_distribution: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnormal\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m----> 9\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_distribution \u001b[38;5;241m=\u001b[39m find_distribution(base_distribution)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/bayesflow/lib/python3.11/site-packages/keras/src/layers/layer.py:266\u001b[0m, in \u001b[0;36mLayer.__init__\u001b[0;34m(self, activity_regularizer, trainable, dtype, autocast, name, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_shape_arg \u001b[38;5;241m=\u001b[39m input_shape_arg\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 266\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    267\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized keyword arguments \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    269\u001b[0m     )\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Will be determined in `build_wrapper`\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Unrecognized keyword arguments passed to FlowMatching: {'depth': 8}"
     ]
    }
   ],
   "source": [
    "# inference_network = bf.networks.FlowMatching(depth = 8, subnet_kwargs=dict(kernel_regularizer=None, dropout_prob = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_network = bf.networks.FlowMatching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = bf.networks.DeepSet(summary_dim = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator = bf.Approximator(\n",
    "    inference_network = inference_network,\n",
    "    summary_network = summary_network,\n",
    "    inference_variables = [\"params\"],\n",
    "    inference_conditions = [\"masks\", \"n_obs\"],\n",
    "    summary_variables = [\"outcomes\", \"designs\"]\n",
    ")\n",
    "\n",
    "approximator.compile(optimizer=\"AdamW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 714ms/step - inference/loss: 4.6162 - loss: 4.6162 - summary/loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x14f5c9150>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approximator.fit(dataset, epochs=1, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = polynomial_reg.sample(batch_size)\n",
    "# ml = polynomial_reg.approximate_log_marginal_likelihood(masks, params, designs, outcomes, approximator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "designs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.7436e+00,  4.3102e+00,  1.1993e-01,  9.0188e-02],\n",
       "        [ 7.1472e+00,  3.6448e+00, -3.2375e-01,  5.1362e-01],\n",
       "        [ 4.2119e+00,  1.7138e+00,  5.9136e-02,  1.1370e-02],\n",
       "        [ 6.1270e+00,  4.9598e+00,  2.7261e-01,  7.6893e-02],\n",
       "        [ 3.3783e+00,  3.1083e+00, -5.6946e-01,  1.1533e+00],\n",
       "        [ 5.7629e+00,  3.2712e+00,  8.4440e-01, -1.3402e-01],\n",
       "        [ 5.2291e+00, -1.1635e-02, -2.0583e-02, -1.3015e-02],\n",
       "        [ 7.6896e-01,  2.2936e+00,  2.0385e-01,  1.8806e-03],\n",
       "        [ 7.0878e+00,  1.4856e+00,  1.0000e-02,  8.7278e-02],\n",
       "        [ 6.3467e+00,  2.7240e-03, -3.1471e-02, -7.7249e-02],\n",
       "        [ 4.3338e+00,  6.2948e-02, -3.7126e-02, -7.8729e-02],\n",
       "        [ 4.9342e+00, -1.0691e-03,  7.4798e-02, -1.8127e-02],\n",
       "        [ 2.3736e+00,  3.0084e+00, -1.9020e-01,  2.0153e-01],\n",
       "        [ 6.1500e+00,  4.0420e+00,  1.0929e+00,  5.5368e-02],\n",
       "        [ 1.7408e+00,  1.1703e-01,  1.2565e-01, -5.2945e-02],\n",
       "        [ 6.0542e+00,  2.8295e+00,  4.2144e-02,  5.0379e-02],\n",
       "        [ 5.5590e+00,  2.9162e+00, -1.0857e+00, -8.8693e-02],\n",
       "        [ 6.0929e+00,  3.0991e+00,  1.5282e-01,  9.4701e-03],\n",
       "        [ 3.0988e+00,  2.8233e+00,  1.0272e+00, -2.3257e-01],\n",
       "        [ 7.9067e+00,  1.8140e+00, -5.2357e-01, -1.9969e-01],\n",
       "        [ 2.4552e+00, -4.8812e-03,  9.1881e-02,  7.0970e-02],\n",
       "        [ 5.8657e+00,  3.3057e+00,  2.9868e-01, -2.4691e-01],\n",
       "        [ 2.8975e+00, -1.2547e-01,  1.7411e-01,  5.6404e-02],\n",
       "        [ 8.5088e+00,  3.2142e+00, -8.5875e-04, -6.0734e-02],\n",
       "        [ 3.9715e+00,  2.0805e+00,  4.6772e-02, -2.6082e-01],\n",
       "        [ 4.6427e+00,  3.2033e+00, -8.5645e-01,  8.1247e-01],\n",
       "        [ 4.7876e+00,  2.4989e+00,  8.4288e-01,  4.2612e-01],\n",
       "        [ 6.1226e+00,  3.7374e+00, -4.0092e-01,  1.8700e-02],\n",
       "        [ 5.2468e+00,  2.9268e+00,  1.8843e-01, -2.2762e-01],\n",
       "        [ 8.5863e+00,  1.3764e-01, -2.6510e-02,  1.0356e-02],\n",
       "        [ 4.9820e+00,  3.3879e+00,  3.9461e-01, -1.0705e+00],\n",
       "        [ 1.0103e+01,  1.4941e+00, -1.2714e-01, -8.0698e-02],\n",
       "        [ 9.0356e+00,  2.5436e+00,  1.8343e-01, -5.7117e-02],\n",
       "        [ 1.9173e+00,  3.2129e-02, -5.0588e-02, -1.1686e-02],\n",
       "        [ 4.0354e+00,  7.2711e-02,  2.4408e-02,  1.2551e-01],\n",
       "        [ 6.1618e+00,  5.5557e+00,  3.8208e-01, -8.4799e-02],\n",
       "        [ 1.9010e+00,  1.6243e+00, -9.2087e-01,  6.8254e-01],\n",
       "        [ 4.0526e+00,  3.2732e+00, -6.8686e-01, -1.0332e-02],\n",
       "        [ 8.0285e+00,  7.7559e-02,  1.3605e-01,  2.0396e-01],\n",
       "        [ 4.9923e+00,  2.8951e+00,  6.2713e-01,  1.5218e-01],\n",
       "        [ 6.8963e+00,  2.3125e+00, -1.1930e+00, -3.8759e-02],\n",
       "        [ 5.0729e+00,  3.0709e+00, -5.2480e-02, -1.8212e-01],\n",
       "        [ 5.5919e+00, -1.2157e-01, -7.8378e-02,  1.9148e-01],\n",
       "        [ 2.5140e+00,  3.4708e+00, -6.0711e-02, -3.0663e-02],\n",
       "        [ 8.1782e+00,  3.4617e+00, -9.3830e-02,  5.1354e-02],\n",
       "        [ 5.5616e+00,  4.0047e+00,  6.6996e-02,  4.9126e-02],\n",
       "        [ 8.2583e+00,  3.2076e+00,  4.2515e-01,  6.6075e-02],\n",
       "        [ 6.2390e+00,  3.4780e+00, -1.8000e-02, -6.1020e-02],\n",
       "        [ 6.5739e+00, -1.5982e-02,  1.3580e-02,  1.6434e-01],\n",
       "        [ 7.9450e+00,  3.3892e+00,  7.4732e-01,  7.5309e-02],\n",
       "        [ 3.4307e+00,  1.4041e-01,  5.2673e-02,  7.9164e-02],\n",
       "        [ 4.5477e+00,  3.3420e+00, -1.1637e-02,  1.3054e-01],\n",
       "        [ 6.2783e+00, -2.3472e-02, -1.7042e-01,  9.3579e-02],\n",
       "        [ 6.4721e+00, -1.7783e-01, -1.3616e-02,  1.9974e-01],\n",
       "        [ 4.2855e+00,  1.9559e-02,  1.5964e-01,  1.1772e-01],\n",
       "        [ 2.4119e+00, -7.1888e-02,  1.3064e-01, -1.3304e-01],\n",
       "        [ 2.3762e+00,  1.1995e+00,  3.2823e-01, -2.0488e-01],\n",
       "        [ 4.3016e+00, -1.2516e-01, -2.3714e-01, -4.5970e-02],\n",
       "        [-5.0397e-01,  2.6457e+00, -1.3864e-02, -3.3064e-02],\n",
       "        [-1.1652e+00, -1.3175e-01, -5.0535e-02, -6.7570e-02],\n",
       "        [ 8.7718e+00,  2.7970e-02, -2.6653e-02,  4.6374e-02],\n",
       "        [ 3.3498e+00,  9.3158e-02,  1.4349e-01,  5.0933e-02],\n",
       "        [ 3.5323e+00,  1.8407e+00, -1.0845e-01, -4.3781e-02],\n",
       "        [ 7.3461e+00,  4.0979e+00, -1.2765e+00, -1.9490e-02]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"params\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator.sample(batch_size, data = {\"outcomes\": Tensor([0]), \"designs\": Tensor([0])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO at last\n",
    "\n",
    "class InferenceDesignApproximator:\n",
    "    def __init__(self, hyperparameters: dict, bf_settings: dict, design_settings: dict):\n",
    "\n",
    "        self.summary_network = ...\n",
    "\n",
    "        # Dataset object: online dataset https://github.com/stefanradev93/BayesFlow/blob/streamlined-backend/bayesflow/datasets/online_dataset.py\n",
    "        self.dataset: MyDataSet\n",
    "\n",
    "        # BayesFlow approximator is encapsuled\n",
    "        self.bf_approximator = bf.approximators.Approximator(..., summary_network, **bf_settings)\n",
    "        \n",
    "        # Design network object is encapsuled\n",
    "        self.design_net = DesignNetwork(..., summary_network, **design_settings)\n",
    "\n",
    "        # Hyperparameters: weight terms to balance losses, etc.\n",
    "        self.hyperparameters = hyperparameters\n",
    "\n",
    "    def train(self, dataset):\n",
    "        # Stage 1: Train Bayesflow, use random design\n",
    "        self.bf_approximator.train(dataset)\n",
    "        self.dataset.stage = 2\n",
    "\n",
    "        # Stage 2: Fix BayesFlow, train design network\n",
    "        self.bf_approximator.freeze_weights() # implement this\n",
    "        self.design_approximator.train(dataset)\n",
    "        self.dataset.stage = 3\n",
    "\n",
    "        # Stage 3: Joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 64\n",
    "num_posterior_samples = 500\n",
    "\n",
    "test_dataset = dataset.__getitem__(0)\n",
    "\n",
    "samples = approximator.sample(batch_shape=(num_test_samples, num_posterior_samples), data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['params', 'summaries'])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
