{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use torch backend\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/bayesflow/lib/python3.11/site-packages/keras/src/backend/torch/numpy.py:870: UserWarning: The operator 'aten::logspace.out' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/miniforge3/conda-bld/libtorch_1715184405838/work/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  torch.logspace(\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import os\n",
    "os.environ[\"KERAS_BACKEND\"] = \"torch\"\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "\n",
    "import keras\n",
    "\n",
    "if keras.backend.backend() == \"torch\":\n",
    "    import torch\n",
    "    print(\"Use torch backend\")\n",
    "    torch.autograd.set_grad_enabled(False)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import bayesflow as bf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayesflow.simulators.simulator import Simulator\n",
    "# from bayesflow.types import Shape, Tensor\n",
    "from torch import Tensor\n",
    "from torch.distributions import Distribution\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_simulators import MyGenericSimulator, LikelihoodBasedModel, ParameterMask, Prior, RandomNumObs\n",
    "from design_networks import RandomDesign, DeepAdaptiveDesign, EmitterNetwork\n",
    "from design_loss import NestedMonteCarlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolynomialRegression(LikelihoodBasedModel):\n",
    "    def __init__(self, mask_sampler, prior_sampler, tau_sampler, design_generator, simulator_var) -> None:\n",
    "        super().__init__(mask_sampler, prior_sampler, tau_sampler, design_generator, simulator_var)\n",
    "\n",
    "    def outcome_likelihood(self, params: Tensor, xi: Tensor, simulator_var: dict) -> Distribution:\n",
    "\n",
    "        xi_powers = torch.stack([torch.ones_like(xi), xi, xi ** 2, xi ** 3], dim=1)\n",
    "        mean = torch.sum(params * xi_powers, dim=-1, keepdim=True)\n",
    "        sigma = simulator_var[\"sigma\"]\n",
    "        return torch.distributions.Normal(mean, sigma)\n",
    "    \n",
    "    def analytical_log_marginal_likelihood(outcomes, params: Tensor, masks: Tensor) -> Tensor:\n",
    "        raise NotImplementedError # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PriorPolynomialReg(Prior):\n",
    "    def __init__(self, delta: Tensor = Tensor([0.1])) -> None:\n",
    "        super().__init__()\n",
    "        self.delta = delta\n",
    "\n",
    "    def dist(self, masks: Tensor) -> [Distribution]:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.masks = masks\n",
    "\n",
    "        default = Tensor([[0, self.delta]])\n",
    "        masks_ = masks.unsqueeze(-1)\n",
    "\n",
    "        prior_0 = torch.where(masks_[:, 0] == 1, Tensor([5, 2]), default)\n",
    "        prior_1 = torch.where(masks_[:, 1] == 1, Tensor([3, 1]), default)\n",
    "        prior_2 = torch.where(masks_[:, 2] == 1, Tensor([0, 0.8]), default)\n",
    "        prior_3 = torch.where(masks_[:, 3] == 1, Tensor([0, 0.5]), default)\n",
    "\n",
    "        hyper_params = torch.stack([prior_0, prior_1, prior_2, prior_3], dim=1)\n",
    "\n",
    "        means = hyper_params[:, :, 0]\n",
    "        sds = hyper_params[:, :, 1]\n",
    "    \n",
    "        dist = torch.distributions.MultivariateNormal(means, scale_tril=torch.stack([torch.diag(sd) for sd in sds]))\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 64\n",
    "batch_size = torch.Size([B])\n",
    "\n",
    "mask_sampler = ParameterMask()\n",
    "masks = mask_sampler(batch_size)\n",
    "prior_sampler = PriorPolynomialReg()\n",
    "params = prior_sampler.sample(masks)\n",
    "likelihood = prior_sampler.log_prob(params, masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of parameter mask torch.Size([64, 4])\n",
      "Shape of parameters torch.Size([64, 4])\n",
      "Shape of likelihood torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "print(f\"Shape of parameter mask {masks.shape}\") # [B, model_dim]\n",
    "print(f\"Shape of parameters {params.shape}\") # [B, param_dim]\n",
    "print(f\"Shape of likelihood {likelihood.shape}\") # [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_design_generator = RandomDesign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 10\n",
    "random_num_obs = RandomNumObs(min_obs = 1, max_obs = T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "polynomial_reg = PolynomialRegression(mask_sampler = mask_sampler,\n",
    "                                      prior_sampler = prior_sampler,\n",
    "                                      tau_sampler = random_num_obs,\n",
    "                                      design_generator = random_design_generator,\n",
    "                                      simulator_var = {\"sigma\": 1.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataSet(keras.utils.PyDataset):\n",
    "    def __init__(self, batch_size: torch.Size, stage: int, initial_generative_model: MyGenericSimulator, design_network: nn.Module = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "        self.stage = stage # stage 1,2,3\n",
    "        self.initial_generative_model = initial_generative_model\n",
    "        self.design_network = design_network\n",
    "\n",
    "    def __getitem__(self, item:int) -> dict[str, Tensor]:\n",
    "        if self.stage == 1:\n",
    "\n",
    "            data = self.initial_generative_model.sample(self.batch_size)\n",
    "            return data\n",
    "\n",
    "        if self.stage == 2:\n",
    "            second_generative_model = 1\n",
    "            data = self.second_generative_model.sampel(self.batch_size, )\n",
    "            return data\n",
    "\n",
    "        if self.stage == 3:\n",
    "            ...\n",
    "            return data\n",
    "    \n",
    "    @property\n",
    "    def num_batches(self):\n",
    "        # infinite dataset\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MyDataSet(batch_size = batch_size, stage = 1, initial_generative_model = polynomial_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference_network = bf.networks.CouplingFlow(depth = 8, subnet_kwargs=dict(kernel_regularizer=None, dropout_prob = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_network = bf.networks.FlowMatching()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_network = bf.networks.DeepSet(summary_dim = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "approximator = bf.Approximator(\n",
    "    inference_network = inference_network,\n",
    "    summary_network = summary_network,\n",
    "    inference_variables = [\"params\"],\n",
    "    inference_conditions = [\"masks\", \"n_obs\"],\n",
    "    summary_variables = [\"outcomes\", \"designs\"]\n",
    ")\n",
    "\n",
    "approximator.compile(optimizer=\"AdamW\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 731ms/step - inference/loss: 4.7153 - loss: 4.7153 - summary/loss: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x12a5c3a90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "approximator.fit(dataset, epochs=1, steps_per_epoch=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO at last\n",
    "\n",
    "class InferenceDesignApproximator:\n",
    "    def __init__(self, hyperparameters: dict, bf_settings: dict, design_settings: dict):\n",
    "\n",
    "        self.summary_network = ...\n",
    "\n",
    "        # Dataset object: online dataset https://github.com/stefanradev93/BayesFlow/blob/streamlined-backend/bayesflow/datasets/online_dataset.py\n",
    "        self.dataset: MyDataSet\n",
    "\n",
    "        # BayesFlow approximator is encapsuled\n",
    "        self.bf_approximator = bf.approximators.Approximator(..., summary_network, **bf_settings)\n",
    "        \n",
    "        # Design network object is encapsuled\n",
    "        self.design_net = DesignNetwork(..., summary_network, **design_settings)\n",
    "\n",
    "        # Hyperparameters: weight terms to balance losses, etc.\n",
    "        self.hyperparameters = hyperparameters\n",
    "\n",
    "    def train(self, dataset):\n",
    "        # Stage 1: Train Bayesflow, use random design\n",
    "        self.bf_approximator.train(dataset)\n",
    "        self.dataset.stage = 2\n",
    "\n",
    "        # Stage 2: Fix BayesFlow, train design network\n",
    "        self.bf_approximator.freeze_weights() # implement this\n",
    "        self.design_approximator.train(dataset)\n",
    "        self.dataset.stage = 3\n",
    "\n",
    "        # Stage 3: Joint training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_test_samples = 64\n",
    "num_posterior_samples = 500\n",
    "\n",
    "test_sims = dataset.__getitem__(0)\n",
    "samples = approximator.sample(batch_shape=(num_test_samples, num_posterior_samples), data=test_sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observed data\n",
    "out = polynomial_reg.sample(torch.Size([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[\"masks\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data = {\"designs\": out[\"designs\"], \"outcomes\": out[\"outcomes\"], \"masks\": out[\"masks\"], \"n_obs\": out[\"n_obs\"]}\n",
    "post_given_obs  = approximator.sample(batch_shape = (1, num_posterior_samples), data = obs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_data[\"masks\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_data = {\"designs\": out[\"designs\"], \"outcomes\": out[\"outcomes\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function dict.values>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_data.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 1])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs_data[\"outcomes\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 2])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bayesflow.utils import filter_concatenate\n",
    "\n",
    "filter_concatenate(obs_data, keys=[\"outcomes\", \"designs\"]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_out = summary_network(filter_concatenate(obs_data, keys=[\"outcomes\", \"designs\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_net = EmitterNetwork(input_dim = 10, hidden_dim = 24, output_dim = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "designs_net = DeepAdaptiveDesign(encoder_net=summary_network,\n",
    "                                 decoder_net = decoder_net,\n",
    "                                 design_shape = torch.Size([1]), \n",
    "                                 summary_variables=[\"outcomes\", \"designs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_batched = torch.randn(64, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_batched.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 1])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_net(summary_batched).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.empty((0, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1]],\n",
      "\n",
      "        [[1]],\n",
      "\n",
      "        [[1]]])\n"
     ]
    }
   ],
   "source": [
    "xi = torch.tensor([1])\n",
    "\n",
    "# Adding two singleton dimensions and repeating\n",
    "B = 3  # Example size for repetition\n",
    "expanded_xi = xi.view(1, 1, 1).repeat(B, 1, 1)\n",
    "\n",
    "print(expanded_xi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expanded_xi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bayesflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
